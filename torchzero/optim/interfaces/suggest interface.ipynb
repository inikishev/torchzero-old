{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections.abc import Sequence, Callable\n",
    "from typing import Any, Literal, Optional\n",
    "import math\n",
    "from functools import partial\n",
    "from glio.imports import *\n",
    "from torchzero.random.random import uniform\n",
    "from torchzero.python_tools import auto_compose, identity\n",
    "\n",
    "SCALE_LITERALS = Literal[None, 'linear', 'log', 'log2', 'log10', 'ln']\n",
    "\n",
    "SCALERS = {\n",
    "    None: identity,\n",
    "    'linear': identity,\n",
    "    'log': torch.log10,\n",
    "    'log2': torch.log2,\n",
    "    'log10': torch.log10,\n",
    "    'ln': torch.log\n",
    "}\n",
    "\n",
    "class XPow:\n",
    "    def __init__(self, base):\n",
    "        self.base = base\n",
    "    def __call__(self, x):\n",
    "        return self.base ** x\n",
    "\n",
    "UNSCALERS= {\n",
    "    None: identity,\n",
    "    'linear': identity,\n",
    "    'log': XPow(10),\n",
    "    'log2': XPow(2),\n",
    "    'log10': XPow(10),\n",
    "    'ln': torch.exp\n",
    "}\n",
    "\n",
    "\n",
    "class ParamNumeric(torch.nn.Module):\n",
    "    def __init__(self, name:str, min:float, max:float, scale:SCALE_LITERALS, mul:float, init: Callable | float | torch.Tensor, tfm:Optional[Callable | Sequence[Callable]]):\n",
    "        super().__init__()\n",
    "        self.name = name\n",
    "        self.min = min\n",
    "        self.max = max\n",
    "        self.scale = scale\n",
    "        self.mul = mul\n",
    "        self.init = init\n",
    "\n",
    "        self.scaler = SCALERS[scale]\n",
    "        self.unscaler = UNSCALERS[scale]\n",
    "        self.true_min = self.unscaler(self.min) * self.mul\n",
    "        self.true_max = self.unscaler(self.max) * self.mul\n",
    "\n",
    "        self.tfm = auto_compose(tfm)\n",
    "\n",
    "        if callable(init):\n",
    "            self.param = torch.nn.Parameter(init(1, self.true_min, self.true_max, dtype=torch.float32), requires_grad = True)\n",
    "        else:\n",
    "            self.param = torch.nn.Parameter(torch.tensor(self.unscaler(init) * self.mul, dtype=torch.float32), requires_grad = True)\n",
    "\n",
    "    def forward(self):\n",
    "        return self.tfm(self.scaler(self.param / self.mul))\n",
    "\n",
    "class ParamInt(ParamNumeric):\n",
    "    def __init__(self, name:str, min:float, max:float, scale:SCALE_LITERALS, mul:float, init: Callable | float | torch.Tensor | Any, tfm:Optional[Callable]):\n",
    "        tfm = Compose(auto_compose(tfm), int)\n",
    "        super().__init__(name = name, min = min, max = max, scale = scale, mul = mul, init = init, tfm=tfm)\n",
    "\n",
    "class ParamFloat(ParamNumeric):\n",
    "    def __init__(self, name:str, min:float, max:float, scale:SCALE_LITERALS, mul:float, init: Callable | float | torch.Tensor, tfm:Optional[Callable]):\n",
    "        tfm = Compose(auto_compose(tfm), float)\n",
    "        super().__init__(name = name, min = min, max = max, scale = scale, mul = mul, init = init, tfm=tfm)\n",
    "\n",
    "def _to_bool(x): return x > 0\n",
    "class ParamBool(ParamNumeric):\n",
    "    def __init__(self, name:str, mul:float, init: Callable | bool | float | torch.Tensor, tfm:Optional[Callable]):\n",
    "        tfm = Compose(auto_compose(tfm), _to_bool)\n",
    "        super().__init__(name = name, min = -1, max = 1, mul = mul, scale=None, init = init, tfm=tfm)\n",
    "\n",
    "def _choose(x, choices:Sequence): return choices[int(x % len(choices))]\n",
    "class ParamCategorical(ParamNumeric):\n",
    "    def __init__(self, name:str, choices: Sequence, mul:float, init: Callable | float | torch.Tensor | Any, tfm:Optional[Callable]):\n",
    "        tfm = Compose(auto_compose(tfm), partial(_choose, choices=choices))\n",
    "\n",
    "        if init in choices: init = choices.index(init)\n",
    "        super().__init__(name = name, min = 0, max = len(choices), mul = mul, scale=None,  init = init, tfm=tfm)\n",
    "\n",
    "\n",
    "class Trial(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def suggest_float(self, name:str, min, max, scale:SCALE_LITERALS = None, mul=1., init = uniform, tfm=None):\n",
    "        if name not in dict(self.named_modules()):\n",
    "            self.add_module(name, ParamFloat(name = name, min = min, max = max, scale = scale, mul = mul, init = init, tfm=tfm))\n",
    "        return getattr(self, name)()\n",
    "\n",
    "    def suggest_int(self, name:str, min, max, scale:SCALE_LITERALS = None, mul=0.01, init = uniform, tfm=None):\n",
    "        if name not in dict(self.named_modules()):\n",
    "            self.add_module(name, ParamInt(name = name, min = min, max = max, scale = scale, mul = mul, init = init, tfm=tfm))\n",
    "        return getattr(self, name)()\n",
    "\n",
    "    def suggest_bool(self, name:str, mul=0.01, init = uniform, tfm=None):\n",
    "        if name not in dict(self.named_modules()):\n",
    "            self.add_module(name, ParamBool(name = name, mul = mul, init = init, tfm=tfm))\n",
    "        return getattr(self, name)()\n",
    "\n",
    "    def suggest_categorical(self, name:str, choices: Sequence, mul=0.01, init = uniform, tfm=None):\n",
    "        if name not in dict(self.named_modules()):\n",
    "            self.add_module(name, ParamCategorical(name = name, choices = choices, mul = mul, init = init, tfm=tfm))\n",
    "        return getattr(self, name)()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Study:\n",
    "    def __init__(self, objective):\n",
    "        self.objective = objective\n",
    "        self.trial = Trial()\n",
    "        self.lowest_loss = self.objective(self.trial)\n",
    "\n",
    "        self.loss_history = []\n",
    "        self.lowest_loss = float('inf')\n",
    "        self.best_params = None\n",
    "\n",
    "    def parameters(self):\n",
    "        return self.trial.parameters()\n",
    "\n",
    "    def step(self):\n",
    "        loss = self.objective(self.trial)\n",
    "\n",
    "        if isinstance(loss, torch.Tensor): float_loss = float(loss.detach().cpu())\n",
    "        else: float_loss = float(loss)\n",
    "        self.loss_history.append(float_loss)\n",
    "\n",
    "        if float_loss < self.lowest_loss:\n",
    "            self.lowest_loss = float_loss\n",
    "            self.best_params = [i.clone() for i in self.parameters()]\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def __call__(self): return self.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8457534934271646e-09\r"
     ]
    }
   ],
   "source": [
    "from torchzero.optim import AcceleratedRandomSearch\n",
    "def objective(trial:Trial):\n",
    "    x = trial.suggest_float(\"x\", -10, 10)\n",
    "    y = trial.suggest_float(\"y\", -10, 10)\n",
    "    return x ** 2 + y ** 2\n",
    "\n",
    "study = Study(objective)\n",
    "optimizer = AcceleratedRandomSearch(study.parameters(), [-10, 10])\n",
    "\n",
    "for _ in range(1000):\n",
    "    optimizer.zero_grad()\n",
    "    loss = optimizer.step(study)\n",
    "    print(loss, end = '\\r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "from is out of bounds for float",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[68], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43muniform\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mF:\\Stuff\\Programming\\AI\\torchzero\\torchzero\\random\\random.py:119\u001b[0m, in \u001b[0;36muniform\u001b[1;34m(shape, low, high, device, requires_grad, dtype)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21muniform\u001b[39m(shape, low, high, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, requires_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m--> 119\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mempty\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequires_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequires_grad\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muniform_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlow\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhigh\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: from is out of bounds for float"
     ]
    }
   ],
   "source": [
    "uniform(10, -float('inf'), float('inf'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
